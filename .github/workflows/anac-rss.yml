name: ANAC News RSS Generator

on:
  schedule:
    - cron: '0 */4 * * *'  # Executa a cada 4 horas
  workflow_dispatch:
  push:
    branches: [ main ]

# Permissões explícitas
permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  generate-feed:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Necessário para histórico completo

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install beautifulsoup4 feedgenerator requests html2text

    - name: Generate RSS feed with debug
      run: |
        # Script Python com verificação de conteúdo
        cat > anac_rss_generator.py << 'EOF'
        import requests
        from bs4 import BeautifulSoup
        from feedgenerator import Rss201rev2Feed
        from datetime import datetime
        import pytz
        import html2text
        import sys

        def debug_log(message):
            print(f"::debug::{message}")
            sys.stdout.flush()

        def clean_text(text):
            return ' '.join(text.strip().split()) if text else ""

        def parse_date(date_str):
            try:
                date_formats = ['%d/%m/%Y %H:%M', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S']
                for fmt in date_formats:
                    try:
                        return datetime.strptime(date_str, fmt).astimezone(pytz.timezone('America/Sao_Paulo'))
                    except ValueError:
                        continue
                return datetime.now(pytz.timezone('America/Sao_Paulo'))
            except:
                return datetime.now(pytz.timezone('America/Sao_Paulo'))

        def get_news_items():
            base_url = "https://www.gov.br/anac/pt-br/noticias"
            headers = {'User-Agent': 'ANAC-RSS-Feed/1.0'}
            
            try:
                debug_log("Fetching ANAC news page")
                response = requests.get(base_url, headers=headers, timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                news_cards = soup.select('div#content-core article.tileItem')
                debug_log(f"Found {len(news_cards)} news articles")
                
                items = []
                for card in news_cards[:5]:  # Process only 5 for testing
                    try:
                        title_tag = card.select_one('h2.tileHeadline a') or card.select_one('h2 a')
                        if not title_tag:
                            continue
                            
                        item = {
                            'title': clean_text(title_tag.get_text()),
                            'link': title_tag['href'] if title_tag['href'].startswith('http') else f"https://www.gov.br{title_tag['href']}",
                            'description': "",
                            'content': "",
                            'date_str': ""
                        }
                        
                        if desc_tag := card.select_one('div.description') or card.select_one('div.tileBody'):
                            item['description'] = clean_text(desc_tag.get_text())
                        
                        if date_tag := card.select_one('span.summary-view-icon') or card.select_one('span.documentPublished'):
                            item['date_str'] = clean_text(date_tag.get_text())
                        
                        debug_log(f"Processing: {item['title']}")
                        items.append(item)
                    except Exception as e:
                        print(f"::warning::Error processing item: {str(e)}")
                
                return items
            except Exception as e:
                print(f"::error::Failed to fetch news: {str(e)}")
                return []

        def generate_feed():
            feed = Rss201rev2Feed(
                title="Notícias da ANAC",
                link="https://www.gov.br/anac/pt-br/noticias",
                description="Últimas notícias da ANAC",
                language="pt-br"
            )
            
            news_items = get_news_items()
            if not news_items:
                print("::error::No news items found!")
                sys.exit(1)
            
            for item in news_items:
                feed.add_item(
                    title=item['title'],
                    link=item['link'],
                    description=item['description'],
                    content=item['content'],
                    pubdate=parse_date(item['date_str']),
                    author="ANAC",
                    unique_id=item['link']
                )
            
            with open('anac-feed.xml', 'w', encoding='utf-8') as f:
                feed.write(f, 'utf-8')
            debug_log("RSS feed generated successfully")

        if __name__ == "__main__":
            generate_feed()
        EOF

        # Executar e verificar saída
        python anac_rss
